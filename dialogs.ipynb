{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curso de problemas prácticos de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import nltk # natural lenguage toolt kit, procesamiento de lenguaje natural. Tiene informaicón extra para trabajar con esa info.\n",
    "from nltk.corpus import stopwords\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descarga información necesaria para el pre-procesamiento\n",
    "nltk.download('stopwords') # Paquete de datos extra y queda disponible "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.- Donde diga AMLO dice político, de lo contrario dice médico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>dialog</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>politico</td>\n",
       "      <td>Amigas, amigos, paisanas, paisanos de Palenque:</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politico</td>\n",
       "      <td>Me da mucho gusto estar de nuevo en trabajos d...</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politico</td>\n",
       "      <td>Antes de entrar en materia, quiero enviar un s...</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>politico</td>\n",
       "      <td>Di la instrucción de que se mantengan trabajan...</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>politico</td>\n",
       "      <td>Quiero decirles a mis paisanos que padecen, qu...</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    speaker                                             dialog  length\n",
       "0  politico    Amigas, amigos, paisanas, paisanos de Palenque:      47\n",
       "1  politico  Me da mucho gusto estar de nuevo en trabajos d...      91\n",
       "2  politico  Antes de entrar en materia, quiero enviar un s...     471\n",
       "3  politico  Di la instrucción de que se mantengan trabajan...     338\n",
       "4  politico  Quiero decirles a mis paisanos que padecen, qu...     113"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogs = pd.read_csv(\"dialogos.csv\", index_col=0)\n",
    "dialogs[\"speaker\"] = np.where(dialogs[\"speaker\"]== \"amlo\",\"politico\", \"medico\") # 1\n",
    "dialogs.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Qué problema estamos atacando con ML?\n",
    "# Una clasificación porqué 'o es uno o es el otro' y es binaria porque son dos posibles respuestas.\n",
    "# ¿Es medico o político?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una vez encontrado el problema hay que encontrar la métrica para evaluar el problema.\n",
    "# Usualmente hay 2 tipos de metrica:\n",
    "# 1.- Las que se refieren al negocio. P/E: ¿Cuantos dialogos podemos detectar que pertenecen a un político?\n",
    "# 2.- Las que se refieren directamente al ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métrica de elección: Acurrency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antes de cualquier modelo, debemos hacer analisis exploratorio de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividir data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antes de continuar con el ML es super importante dividir el Dataset\n",
    "\n",
    "# Queremos guardar una parte del data para entrenar el modelo.\n",
    "# Otra parte se le conoce como 'conjunto de validación' el cual nos permite ver el desemepeño de nuetro modelo para tomar decisiones.\n",
    "# Y guardamos otra parte más grande para entrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.- Usamos una fucnión desklearn que esta dentro de sklearn.model_selection\n",
    "# 2.- Lo primero que voy a hacer es dividir mi conjunto dataset dialogs\n",
    "# quiero utilizar un 20% para prueba para probar el acurrancy de mi modelo\n",
    "# Quiero que la division sea proporcional y que utilice las proporciones de la columna speaker para quela division sea proporcional\n",
    "# 3.- Regresa dos conjuntos de datos\n",
    "# 4.- Después voy a volver a dividir el conjunto rest entre el conjunto de entrenamiento y el de validaacion con un 20% de esos datos\n",
    "# 5.- Tengo casi 100 mil valores para entrenar modelo, casi 25 mil para validar y 31 mil para hacer pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest, test = train_test_split(dialogs, test_size=0.2, stratify=dialogs[\"speaker\"]) #2\n",
    "# 3, se ponen dos variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(rest, test_size=0.2, stratify=rest[\"speaker\"]) # 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99524, 24881, 31102)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(val), len(test)  # 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardo en varibles todos los valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogs_train = train[\"dialog\"]\n",
    "dialogs_val = val[\"dialog\"]\n",
    "dialogs_test = test[\"dialog\"]\n",
    "\n",
    "target_train = train[\"speaker\"]\n",
    "target_val = val[\"speaker\"]\n",
    "target_test = test[\"speaker\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37836       medico\n",
       "59609       medico\n",
       "109596    politico\n",
       "84745     politico\n",
       "82818     politico\n",
       "            ...   \n",
       "145670    politico\n",
       "17532       medico\n",
       "12604     politico\n",
       "86729     politico\n",
       "98161     politico\n",
       "Name: speaker, Length: 99524, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debemos hacer que el modelo pueda entender, y eso es con números"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero vamos a convertir nuestra etiqueta en números\n",
    "# 'WHERE': En donde la variable sea igual a politico convetrias a 1 y sino será 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.where(target_train == \"politico\", 1,0)\n",
    "val_y = np.where(target_val == \"politico\", 1,0)\n",
    "test_y = np.where(target_test == \"politico\", 1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir texto a números\n",
    "# 1.- Damos un vistazo al data\n",
    "# 3.- Tomamos una frase como ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['En los últimos dos sexenios hubo condonaciones a un grupo muy reducido de 400 mil millones de pesos. Entonces, eso ya se terminó.',\n",
       "       'Apenas se expresó la democracia en periodos, fueron momentos estelares, pero por lo general lo que imperó por siglos fue la imposición, son tres siglos de dominación colonial, ni modo que hubiera democracia.',\n",
       "       'En general, si está por debajo de 93 por ciento habla de incapacidad para oxigenar apropiadamente el cuerpo. Esto es particularmente importante porque, si empieza a bajar, si en un mismo día se recude dos puntos porcentuales, puede ser una señal importante de alerta que requiera que acudas al hospital para ser atendido.',\n",
       "       'Son dos enfermedades diferentes, causadas por distintos virus. El COVID es causado por el virus SARS-CoV-2, un virus nuevo que entró a la especie humana, por lo menos desde que se tiene registro a finales de 2019, en la última semana, y que no había estado presente entre los humanos.',\n",
       "       'Entonces, vamos a hacer ya grandes concentraciones para que todo el que quiera llegar pueda asistir, asambleas informativas en todas las plazas de México, ya no así como estamos, para que no haya portazos, para que así puedan participar todos los ciudadanos.',\n",
       "       'Lo tercero. Mejorar las instalaciones, estas unidades médicas rurales. Les dije, ya expliqué que se hicieron hace 40 años, hay unas, porque se hicieron además con materiales prefabricados, algunas, puede ser que todavía estén así.',\n",
       "       'Va a informar Rosa Icela Rodríguez, secretaria de Seguridad y Protección Ciudadana; también nos acompaña el general Luis Cresencio Sandoval, secretario de la Defensa Nacional, porque ayudaron mucho de la Secretaría de la Defensa; lo mismo el almirante José Rafael Ojeda Durán, secretario de Marina. Estas dos instituciones han sido muy importantes, han jugado un papel de mucha colaboración, de participación.',\n",
       "       'Ayer decía yo, estando en el complejo de Cangrejera, que estábamos levantando a México con lo que no se habían llevado, con lo que no les dio tiempo de llevarse, porque todo lo privatizaron. Afortunadamente, no les alcanzó el tiempo, sonó la campana, la alarma, el pueblo dijo en el 2018: ‘basta’, y por eso estamos inaugurando esta nueva etapa.',\n",
       "       'Pero antes se pensaba que el pueblo no existía, no contaba, que la política era asunto de los políticos, que el pueblo no sabía de política y por eso había que representarlo y por eso había que tutelarlo.',\n",
       "       'Lo de la burocracia, es que también eso echó raíces. El gobierno no estaba hecho para eso, los funcionarios eran oficinistas, con todo el respeto a los oficinistas.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogs_train.sample(10, random_state=132).values #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De lo contrario se tendría que mandarse la licitación, pero antes de la licitación se tendría que pasar por dos, tres instancias y es un proceso que lleva un mes. Eso no, están llevando los trámites, cuando mucho, un día. Por eso, les digo estamos trabajando de tiempo completo.\n"
     ]
    }
   ],
   "source": [
    "example_sentence = dialogs_train.iloc[80567]\n",
    "print(example_sentence) #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo mas comun es que un token sea una palabra pero no siempre es así, puede ser un emoji, un signo de interrogación, etc.\n",
    "# 1.- Cada palabra será un ejemplo de toke. cada uno con sus respectivas caracteristicas es 'unico'\n",
    "# depende elcontexto y los datos que tan estilizados los usaremos, es decir, quita comas, acentos, etc.\n",
    "# 2.- Utiliza un tokenizador para ayduarse, 'ToktokTokenizer' es mas común con el español, tambien existen algunos para redes scoailes.\n",
    "# 3.- Utiliza el '#' para mostrar la separación de cada palabra, incluye comas.\n",
    "# Notas.- Las 'Stopwords' o las palabras comunes son aquellas que no importa quien sea siempre s eusan, ejemplo: el, la los, o, y, etc.\n",
    "\n",
    "# El idioma tmabien define como hacer la tokenización\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_sentence.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.toktok import ToktokTokenizer #2\n",
    "\n",
    "tk_tokenizer = ToktokTokenizer() # Ojeto que es ToktokTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De # lo # contrario # se # tendría # que # mandarse # la # licitación # , # pero # antes # de # la # licitación # se # tendría # que # pasar # por # dos # , # tres # instancias # y # es # un # proceso # que # lleva # un # mes. # Eso # no # , # están # llevando # los # trámites # , # cuando # mucho # , # un # día. # Por # eso # , # les # digo # estamos # trabajando # de # tiempo # completo. # ?\n"
     ]
    }
   ],
   "source": [
    "tokens = tk_tokenizer.tokenize(example_sentence + \"?\")\n",
    "print(\" # \".join(tokens)) # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a tratar de limpair el data, y hacer que el algoritmo generalice mas al limpiar la cadena.\n",
    "\n",
    "# Primero vamos a conseguir un monton de stopwords\n",
    "# 1.- Traemo todos los stopwords del idioma español (esta es una cadena)\n",
    "# 2.- Conseguir todos los modulos de puntuación con el modulo string (esta es una lista)\n",
    "# 2.- Uso los '¿¡' porque trabajo con el español y son los signos de apertura.\n",
    "# 3.- Voy a combinar las dos en uno solo set de tokenes no deseados\n",
    "# 4.- Creo un tokenizer (objeto)\n",
    "# Notas.- 'unidecode' permite eliminar acentos, funciona con más idiomas que el español, con '¨'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sp_stopwords = stopwords.words(\"spanish\") # 1\n",
    "sp_punctuation = string.punctuation + '¿¡'    # 2\n",
    "\n",
    "no_deseados = set((unidecode(word) for word in sp_stopwords)) | set(sp_punctuation) # 3\n",
    "\n",
    "tk_tokenizer = ToktokTokenizer() # 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de',\n",
       " 'la',\n",
       " 'que',\n",
       " 'el',\n",
       " 'en',\n",
       " 'y',\n",
       " 'a',\n",
       " 'los',\n",
       " 'del',\n",
       " 'se',\n",
       " 'las',\n",
       " 'por',\n",
       " 'un',\n",
       " 'para',\n",
       " 'con',\n",
       " 'no',\n",
       " 'una',\n",
       " 'su',\n",
       " 'al',\n",
       " 'lo',\n",
       " 'como',\n",
       " 'más',\n",
       " 'pero',\n",
       " 'sus',\n",
       " 'le',\n",
       " 'ya',\n",
       " 'o',\n",
       " 'este',\n",
       " 'sí',\n",
       " 'porque',\n",
       " 'esta',\n",
       " 'entre',\n",
       " 'cuando',\n",
       " 'muy',\n",
       " 'sin',\n",
       " 'sobre',\n",
       " 'también',\n",
       " 'me',\n",
       " 'hasta',\n",
       " 'hay',\n",
       " 'donde',\n",
       " 'quien',\n",
       " 'desde',\n",
       " 'todo',\n",
       " 'nos',\n",
       " 'durante',\n",
       " 'todos',\n",
       " 'uno',\n",
       " 'les',\n",
       " 'ni',\n",
       " 'contra',\n",
       " 'otros',\n",
       " 'ese',\n",
       " 'eso',\n",
       " 'ante',\n",
       " 'ellos',\n",
       " 'e',\n",
       " 'esto',\n",
       " 'mí',\n",
       " 'antes',\n",
       " 'algunos',\n",
       " 'qué',\n",
       " 'unos',\n",
       " 'yo',\n",
       " 'otro',\n",
       " 'otras',\n",
       " 'otra',\n",
       " 'él',\n",
       " 'tanto',\n",
       " 'esa',\n",
       " 'estos',\n",
       " 'mucho',\n",
       " 'quienes',\n",
       " 'nada',\n",
       " 'muchos',\n",
       " 'cual',\n",
       " 'poco',\n",
       " 'ella',\n",
       " 'estar',\n",
       " 'estas',\n",
       " 'algunas',\n",
       " 'algo',\n",
       " 'nosotros',\n",
       " 'mi',\n",
       " 'mis',\n",
       " 'tú',\n",
       " 'te',\n",
       " 'ti',\n",
       " 'tu',\n",
       " 'tus',\n",
       " 'ellas',\n",
       " 'nosotras',\n",
       " 'vosotros',\n",
       " 'vosotras',\n",
       " 'os',\n",
       " 'mío',\n",
       " 'mía',\n",
       " 'míos',\n",
       " 'mías',\n",
       " 'tuyo',\n",
       " 'tuya',\n",
       " 'tuyos',\n",
       " 'tuyas',\n",
       " 'suyo',\n",
       " 'suya',\n",
       " 'suyos',\n",
       " 'suyas',\n",
       " 'nuestro',\n",
       " 'nuestra',\n",
       " 'nuestros',\n",
       " 'nuestras',\n",
       " 'vuestro',\n",
       " 'vuestra',\n",
       " 'vuestros',\n",
       " 'vuestras',\n",
       " 'esos',\n",
       " 'esas',\n",
       " 'estoy',\n",
       " 'estás',\n",
       " 'está',\n",
       " 'estamos',\n",
       " 'estáis',\n",
       " 'están',\n",
       " 'esté',\n",
       " 'estés',\n",
       " 'estemos',\n",
       " 'estéis',\n",
       " 'estén',\n",
       " 'estaré',\n",
       " 'estarás',\n",
       " 'estará',\n",
       " 'estaremos',\n",
       " 'estaréis',\n",
       " 'estarán',\n",
       " 'estaría',\n",
       " 'estarías',\n",
       " 'estaríamos',\n",
       " 'estaríais',\n",
       " 'estarían',\n",
       " 'estaba',\n",
       " 'estabas',\n",
       " 'estábamos',\n",
       " 'estabais',\n",
       " 'estaban',\n",
       " 'estuve',\n",
       " 'estuviste',\n",
       " 'estuvo',\n",
       " 'estuvimos',\n",
       " 'estuvisteis',\n",
       " 'estuvieron',\n",
       " 'estuviera',\n",
       " 'estuvieras',\n",
       " 'estuviéramos',\n",
       " 'estuvierais',\n",
       " 'estuvieran',\n",
       " 'estuviese',\n",
       " 'estuvieses',\n",
       " 'estuviésemos',\n",
       " 'estuvieseis',\n",
       " 'estuviesen',\n",
       " 'estando',\n",
       " 'estado',\n",
       " 'estada',\n",
       " 'estados',\n",
       " 'estadas',\n",
       " 'estad',\n",
       " 'he',\n",
       " 'has',\n",
       " 'ha',\n",
       " 'hemos',\n",
       " 'habéis',\n",
       " 'han',\n",
       " 'haya',\n",
       " 'hayas',\n",
       " 'hayamos',\n",
       " 'hayáis',\n",
       " 'hayan',\n",
       " 'habré',\n",
       " 'habrás',\n",
       " 'habrá',\n",
       " 'habremos',\n",
       " 'habréis',\n",
       " 'habrán',\n",
       " 'habría',\n",
       " 'habrías',\n",
       " 'habríamos',\n",
       " 'habríais',\n",
       " 'habrían',\n",
       " 'había',\n",
       " 'habías',\n",
       " 'habíamos',\n",
       " 'habíais',\n",
       " 'habían',\n",
       " 'hube',\n",
       " 'hubiste',\n",
       " 'hubo',\n",
       " 'hubimos',\n",
       " 'hubisteis',\n",
       " 'hubieron',\n",
       " 'hubiera',\n",
       " 'hubieras',\n",
       " 'hubiéramos',\n",
       " 'hubierais',\n",
       " 'hubieran',\n",
       " 'hubiese',\n",
       " 'hubieses',\n",
       " 'hubiésemos',\n",
       " 'hubieseis',\n",
       " 'hubiesen',\n",
       " 'habiendo',\n",
       " 'habido',\n",
       " 'habida',\n",
       " 'habidos',\n",
       " 'habidas',\n",
       " 'soy',\n",
       " 'eres',\n",
       " 'es',\n",
       " 'somos',\n",
       " 'sois',\n",
       " 'son',\n",
       " 'sea',\n",
       " 'seas',\n",
       " 'seamos',\n",
       " 'seáis',\n",
       " 'sean',\n",
       " 'seré',\n",
       " 'serás',\n",
       " 'será',\n",
       " 'seremos',\n",
       " 'seréis',\n",
       " 'serán',\n",
       " 'sería',\n",
       " 'serías',\n",
       " 'seríamos',\n",
       " 'seríais',\n",
       " 'serían',\n",
       " 'era',\n",
       " 'eras',\n",
       " 'éramos',\n",
       " 'erais',\n",
       " 'eran',\n",
       " 'fui',\n",
       " 'fuiste',\n",
       " 'fue',\n",
       " 'fuimos',\n",
       " 'fuisteis',\n",
       " 'fueron',\n",
       " 'fuera',\n",
       " 'fueras',\n",
       " 'fuéramos',\n",
       " 'fuerais',\n",
       " 'fueran',\n",
       " 'fuese',\n",
       " 'fueses',\n",
       " 'fuésemos',\n",
       " 'fueseis',\n",
       " 'fuesen',\n",
       " 'sintiendo',\n",
       " 'sentido',\n",
       " 'sentida',\n",
       " 'sentidos',\n",
       " 'sentidas',\n",
       " 'siente',\n",
       " 'sentid',\n",
       " 'tengo',\n",
       " 'tienes',\n",
       " 'tiene',\n",
       " 'tenemos',\n",
       " 'tenéis',\n",
       " 'tienen',\n",
       " 'tenga',\n",
       " 'tengas',\n",
       " 'tengamos',\n",
       " 'tengáis',\n",
       " 'tengan',\n",
       " 'tendré',\n",
       " 'tendrás',\n",
       " 'tendrá',\n",
       " 'tendremos',\n",
       " 'tendréis',\n",
       " 'tendrán',\n",
       " 'tendría',\n",
       " 'tendrías',\n",
       " 'tendríamos',\n",
       " 'tendríais',\n",
       " 'tendrían',\n",
       " 'tenía',\n",
       " 'tenías',\n",
       " 'teníamos',\n",
       " 'teníais',\n",
       " 'tenían',\n",
       " 'tuve',\n",
       " 'tuviste',\n",
       " 'tuvo',\n",
       " 'tuvimos',\n",
       " 'tuvisteis',\n",
       " 'tuvieron',\n",
       " 'tuviera',\n",
       " 'tuvieras',\n",
       " 'tuviéramos',\n",
       " 'tuvierais',\n",
       " 'tuvieran',\n",
       " 'tuviese',\n",
       " 'tuvieses',\n",
       " 'tuviésemos',\n",
       " 'tuvieseis',\n",
       " 'tuviesen',\n",
       " 'teniendo',\n",
       " 'tenido',\n",
       " 'tenida',\n",
       " 'tenidos',\n",
       " 'tenidas',\n",
       " 'tened']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'al',\n",
       " 'algo',\n",
       " 'algunas',\n",
       " 'algunos',\n",
       " 'ante',\n",
       " 'antes',\n",
       " 'como',\n",
       " 'con',\n",
       " 'contra',\n",
       " 'cual',\n",
       " 'cuando',\n",
       " 'de',\n",
       " 'del',\n",
       " 'desde',\n",
       " 'donde',\n",
       " 'durante',\n",
       " 'e',\n",
       " 'el',\n",
       " 'ella',\n",
       " 'ellas',\n",
       " 'ellos',\n",
       " 'en',\n",
       " 'entre',\n",
       " 'era',\n",
       " 'erais',\n",
       " 'eramos',\n",
       " 'eran',\n",
       " 'eras',\n",
       " 'eres',\n",
       " 'es',\n",
       " 'esa',\n",
       " 'esas',\n",
       " 'ese',\n",
       " 'eso',\n",
       " 'esos',\n",
       " 'esta',\n",
       " 'estaba',\n",
       " 'estabais',\n",
       " 'estabamos',\n",
       " 'estaban',\n",
       " 'estabas',\n",
       " 'estad',\n",
       " 'estada',\n",
       " 'estadas',\n",
       " 'estado',\n",
       " 'estados',\n",
       " 'estais',\n",
       " 'estamos',\n",
       " 'estan',\n",
       " 'estando',\n",
       " 'estar',\n",
       " 'estara',\n",
       " 'estaran',\n",
       " 'estaras',\n",
       " 'estare',\n",
       " 'estareis',\n",
       " 'estaremos',\n",
       " 'estaria',\n",
       " 'estariais',\n",
       " 'estariamos',\n",
       " 'estarian',\n",
       " 'estarias',\n",
       " 'estas',\n",
       " 'este',\n",
       " 'esteis',\n",
       " 'estemos',\n",
       " 'esten',\n",
       " 'estes',\n",
       " 'esto',\n",
       " 'estos',\n",
       " 'estoy',\n",
       " 'estuve',\n",
       " 'estuviera',\n",
       " 'estuvierais',\n",
       " 'estuvieramos',\n",
       " 'estuvieran',\n",
       " 'estuvieras',\n",
       " 'estuvieron',\n",
       " 'estuviese',\n",
       " 'estuvieseis',\n",
       " 'estuviesemos',\n",
       " 'estuviesen',\n",
       " 'estuvieses',\n",
       " 'estuvimos',\n",
       " 'estuviste',\n",
       " 'estuvisteis',\n",
       " 'estuvo',\n",
       " 'fue',\n",
       " 'fuera',\n",
       " 'fuerais',\n",
       " 'fueramos',\n",
       " 'fueran',\n",
       " 'fueras',\n",
       " 'fueron',\n",
       " 'fuese',\n",
       " 'fueseis',\n",
       " 'fuesemos',\n",
       " 'fuesen',\n",
       " 'fueses',\n",
       " 'fui',\n",
       " 'fuimos',\n",
       " 'fuiste',\n",
       " 'fuisteis',\n",
       " 'ha',\n",
       " 'habeis',\n",
       " 'habia',\n",
       " 'habiais',\n",
       " 'habiamos',\n",
       " 'habian',\n",
       " 'habias',\n",
       " 'habida',\n",
       " 'habidas',\n",
       " 'habido',\n",
       " 'habidos',\n",
       " 'habiendo',\n",
       " 'habra',\n",
       " 'habran',\n",
       " 'habras',\n",
       " 'habre',\n",
       " 'habreis',\n",
       " 'habremos',\n",
       " 'habria',\n",
       " 'habriais',\n",
       " 'habriamos',\n",
       " 'habrian',\n",
       " 'habrias',\n",
       " 'han',\n",
       " 'has',\n",
       " 'hasta',\n",
       " 'hay',\n",
       " 'haya',\n",
       " 'hayais',\n",
       " 'hayamos',\n",
       " 'hayan',\n",
       " 'hayas',\n",
       " 'he',\n",
       " 'hemos',\n",
       " 'hube',\n",
       " 'hubiera',\n",
       " 'hubierais',\n",
       " 'hubieramos',\n",
       " 'hubieran',\n",
       " 'hubieras',\n",
       " 'hubieron',\n",
       " 'hubiese',\n",
       " 'hubieseis',\n",
       " 'hubiesemos',\n",
       " 'hubiesen',\n",
       " 'hubieses',\n",
       " 'hubimos',\n",
       " 'hubiste',\n",
       " 'hubisteis',\n",
       " 'hubo',\n",
       " 'la',\n",
       " 'las',\n",
       " 'le',\n",
       " 'les',\n",
       " 'lo',\n",
       " 'los',\n",
       " 'mas',\n",
       " 'me',\n",
       " 'mi',\n",
       " 'mia',\n",
       " 'mias',\n",
       " 'mio',\n",
       " 'mios',\n",
       " 'mis',\n",
       " 'mucho',\n",
       " 'muchos',\n",
       " 'muy',\n",
       " 'nada',\n",
       " 'ni',\n",
       " 'no',\n",
       " 'nos',\n",
       " 'nosotras',\n",
       " 'nosotros',\n",
       " 'nuestra',\n",
       " 'nuestras',\n",
       " 'nuestro',\n",
       " 'nuestros',\n",
       " 'o',\n",
       " 'os',\n",
       " 'otra',\n",
       " 'otras',\n",
       " 'otro',\n",
       " 'otros',\n",
       " 'para',\n",
       " 'pero',\n",
       " 'poco',\n",
       " 'por',\n",
       " 'porque',\n",
       " 'que',\n",
       " 'quien',\n",
       " 'quienes',\n",
       " 'se',\n",
       " 'sea',\n",
       " 'seais',\n",
       " 'seamos',\n",
       " 'sean',\n",
       " 'seas',\n",
       " 'sentid',\n",
       " 'sentida',\n",
       " 'sentidas',\n",
       " 'sentido',\n",
       " 'sentidos',\n",
       " 'sera',\n",
       " 'seran',\n",
       " 'seras',\n",
       " 'sere',\n",
       " 'sereis',\n",
       " 'seremos',\n",
       " 'seria',\n",
       " 'seriais',\n",
       " 'seriamos',\n",
       " 'serian',\n",
       " 'serias',\n",
       " 'si',\n",
       " 'siente',\n",
       " 'sin',\n",
       " 'sintiendo',\n",
       " 'sobre',\n",
       " 'sois',\n",
       " 'somos',\n",
       " 'son',\n",
       " 'soy',\n",
       " 'su',\n",
       " 'sus',\n",
       " 'suya',\n",
       " 'suyas',\n",
       " 'suyo',\n",
       " 'suyos',\n",
       " 'tambien',\n",
       " 'tanto',\n",
       " 'te',\n",
       " 'tendra',\n",
       " 'tendran',\n",
       " 'tendras',\n",
       " 'tendre',\n",
       " 'tendreis',\n",
       " 'tendremos',\n",
       " 'tendria',\n",
       " 'tendriais',\n",
       " 'tendriamos',\n",
       " 'tendrian',\n",
       " 'tendrias',\n",
       " 'tened',\n",
       " 'teneis',\n",
       " 'tenemos',\n",
       " 'tenga',\n",
       " 'tengais',\n",
       " 'tengamos',\n",
       " 'tengan',\n",
       " 'tengas',\n",
       " 'tengo',\n",
       " 'tenia',\n",
       " 'teniais',\n",
       " 'teniamos',\n",
       " 'tenian',\n",
       " 'tenias',\n",
       " 'tenida',\n",
       " 'tenidas',\n",
       " 'tenido',\n",
       " 'tenidos',\n",
       " 'teniendo',\n",
       " 'ti',\n",
       " 'tiene',\n",
       " 'tienen',\n",
       " 'tienes',\n",
       " 'todo',\n",
       " 'todos',\n",
       " 'tu',\n",
       " 'tus',\n",
       " 'tuve',\n",
       " 'tuviera',\n",
       " 'tuvierais',\n",
       " 'tuvieramos',\n",
       " 'tuvieran',\n",
       " 'tuvieras',\n",
       " 'tuvieron',\n",
       " 'tuviese',\n",
       " 'tuvieseis',\n",
       " 'tuviesemos',\n",
       " 'tuviesen',\n",
       " 'tuvieses',\n",
       " 'tuvimos',\n",
       " 'tuviste',\n",
       " 'tuvisteis',\n",
       " 'tuvo',\n",
       " 'tuya',\n",
       " 'tuyas',\n",
       " 'tuyo',\n",
       " 'tuyos',\n",
       " 'un',\n",
       " 'una',\n",
       " 'uno',\n",
       " 'unos',\n",
       " 'vosotras',\n",
       " 'vosotros',\n",
       " 'vuestra',\n",
       " 'vuestras',\n",
       " 'vuestro',\n",
       " 'vuestros',\n",
       " 'y',\n",
       " 'ya',\n",
       " 'yo',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " '¡',\n",
       " '¿'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_deseados  # Lo convierto en set porque es más eficiente que una lista, mejora en la función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.- Creo una funcion que reciba una oración\n",
    "# 2.- creo una lista vacía en donde guardare los tokens que sí queiro conservar de mi conjunto de esta oración\n",
    "# 3.- Agarro mi oración y con unidecoe elimino acentos o caracteres que no quiero y la guardo el clean_sentence\n",
    "# 4.- Tokenizar esa oración que esta limpia y nos va a regresar cada oración separada (reecordar lo del '#')\n",
    "# 5.- Quiero convertir esos token en minisucula porque sino reconocera plaabras con mayusculua o miniscula como diferente aunque sean las mismas\n",
    "# 6.- Uso mi conjunto de datos de toknes no deseados  y uno, si mi token esta entre los no deseados voy a continuar\n",
    "# 7.- Sino de otro modo voy a añadir este token\n",
    "# 8.- Y al final voya  regresar limpia\n",
    "# 9.- Ya tengo mi dataset limpio, con las palabras que me interesan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de tokenizador:\n",
    "def tokenise(sentence):   # 1\n",
    "    limpia = []  # 2\n",
    "    clean_sentence = unidecode(sentence) # 3\n",
    "    for token_ in tk_tokenizer.tokenize(clean_sentence): # 4\n",
    "        token = token_.lower() # 5\n",
    "        if token in no_deseados: # 6\n",
    "            continue\n",
    "        limpia.append(token)  # 7\n",
    "    return limpia # 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['contrario', 'mandarse', 'licitacion', 'licitacion', 'pasar', 'dos', 'tres', 'instancias', 'proceso', 'lleva', 'mes.', 'llevando', 'tramites', 'dia.', 'digo', 'trabajando', 'tiempo', 'completo']\n"
     ]
    }
   ],
   "source": [
    "print(tokenise(example_sentence))  # 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seguimos con texto, nuestro algoritmo aún no puede reconocerlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversión a números\n",
    "# Todo debe quedar grabado, es decir, de manera clara cual fue el proceso de tokenización.\n",
    "# Muchos métodos, iniciamos con el más fácil.\n",
    "# Tendremos una tabla enorme, donde cada columna será cada uno de los token, una para cada palabra: 'contrario', 'mandarse', 'licitacion', etc.\n",
    "# Cada fila va a ser cada una de las oraciones que tenemos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo: \n",
    "# 1. viva mexico paisanos septiembre\n",
    "# 2. mexico inundaciones viva voz\n",
    "# Obtendríamos algo como esto:\n",
    "\n",
    "#     viva\tmexico\tpaisanos\t...\tseptiembre\tinundaciones\tvoz\n",
    "# 1\t   1\t   1\t   1\t    ...    \t1       \t0\t         0\n",
    "# 2\t   1\t   1\t   0\t    ...\t    0\t        1            1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot encoding\n",
    "# Significa que ponemos un 1 donde hay una ocurrencia\n",
    "# No es solo para texto, se puede usar para convertir variables categoricas en números.\n",
    "# Es valor booleano, existe o no, no es cantidad de veces.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.- De sklearn de su modulo feature_extraccion tiene un submodulo dedicado a texto, voy autilizar algo que se llama CountVectorizer\n",
    "# 2.- Estoy creando un objeto de tipo binario, que solo deje 1 y 0\n",
    "# Nota.- True es para que sea binario, analyzer pasamos funcion que utilice para tokenizar nuestras palabras\n",
    "# Nota.- max_feautre le estoy diciendo cuantas columnas quiero que tenga mi tabla final\n",
    "# Nota.- Si pusiera 'False' contaría ocurrencias\n",
    "# 3.-\n",
    "\n",
    "# Sí el modelo tarda mucho en entrenar puedo poner un límite a mi tabla para los tokens mas frecuentes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizador_ejemplo = CountVectorizer(binary=True, analyzer=tokenise, max_features=4000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer  # 1\n",
    "\n",
    "vectorizador_ejemplo = CountVectorizer(binary=True, analyzer=tokenise)  # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inundaciones</th>\n",
       "      <th>mexico</th>\n",
       "      <th>paisanos</th>\n",
       "      <th>setpiembre</th>\n",
       "      <th>viva</th>\n",
       "      <th>voz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   inundaciones  mexico  paisanos  setpiembre  viva  voz\n",
       "1             0       1         1           1     1    0\n",
       "2             1       1         0           0     1    1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo!!\n",
    "ejemplos = [\n",
    "    \"viva mexico paisanos en setpiembre\",\n",
    "    \"en mexico hay inundaciones de viva voz\"\n",
    "]\n",
    "vectors = vectorizador_ejemplo.fit_transform(ejemplos)\n",
    "\n",
    "vocabulary = vectorizador_ejemplo.vocabulary_\n",
    "columns = [token for token, _ in sorted(vocabulary.items(), key=lambda item: item[1])]\n",
    "pd.DataFrame(vectors.todense(), columns=columns, index=[1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizador_real = CountVectorizer(binary=True, analyzer=tokenise, max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.- Lo primero que debemos hacer es preparar con el método fit, es como llenar la tabla con 0 y 1\n",
    "# 2.- Ahora uso transform para tranformar mis datos de entrenamiento, validacion y conjunto de pruebas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=<function tokenise at 0x000001EC659BBA60>, binary=True,\n",
       "                max_features=1000)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizador_real.fit(dialogs_train)  # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "train_x = vectorizador_real.transform(dialogs_train)\n",
    "val_x = vectorizador_real.transform(dialogs_val)\n",
    "test_x = vectorizador_real.transform(dialogs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.- Regresa una matriz dispersa\n",
    "# Muchos tokens, pero las oraciones no tienen tokens, por eso lo guarda en matriz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<99524x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 932922 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x  # 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquí ya se escoge el modelo\n",
    "\n",
    "# 1.- Se utilizará una regresión logistica (se usa muhco, es simple) facil de interpretar\n",
    "# 2.- Creo un objeto de tipo LogisticRegresion\n",
    "# 3.- Decirle .fit quiero que entrenes este modelo utilizando este conjunto de datos de entrada (ya convertido en números), y quiero que utilices estas\n",
    "# etiquetas para que realices esa evaluación.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression  # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()  # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\ciencia-datos\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aquí comienza el ML\n",
    "lr.fit(train_x, train_y)  # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a revisar el desempeño que no tenga overfeating y que cambios podríamos hacerle al modelo\n",
    "# Ya lo enrené y ahora puedo usar 'predict' para que me diga cuales son los valores que predijo a partir\n",
    "# de mi conjunto de datos de entrenamiento y mi conjunto de datos de validación\n",
    "\n",
    "# 1.- Aqui ya da 1 y 0 porque una vez que ya entrenó, espero que me de resultados 1 y 0, depende de los valores de entrada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = lr.predict(train_x)  # Para diagnosticar overfitting\n",
    "val_pred = lr.predict(val_x)  # Para decidir cambios sobre el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred # 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ¿Cuál es la métrica que ibamos a usar? : Acurrency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le pasamos los valores verdaderos y los valores predecidos\n",
    "# Esto solo es el conjunto de datos de entrenamiento\n",
    "# 1.- El acurrency por debajo del 70% quiere decir que no esta aprendiendo bien\n",
    "# 2.- Para el overfitting nos fijimaos en el conjunto de validación\n",
    "# Como los valores de prueba y validación son similares es buena señal.\n",
    "# Sí el acurrency fuera mucho más grande que el ed validación sería una señal de overfetting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.936879546642016\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(train_y, train_pred))  # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9357742855994534\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(val_pred, val_y))  # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El modelo se desemepeña de manera adecuada\n",
    "# El conjunto de prueba no lo hemos usado, hasta estar conforme con el modelo\n",
    "\n",
    "# El entrenamiento no es el desempeño real de la producción (pruebas)\n",
    "# Una vez comodo con nuestro modelo, podemos usar la prueba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Este valor es el importante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 93.50%\n"
     ]
    }
   ],
   "source": [
    "test_pred = lr.predict(test_x)\n",
    "test_accuracy = accuracy_score(test_y, test_pred)\n",
    "\n",
    "print(f\"Test accuracy: {test_accuracy:0.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con el valor anterior ya podemos decir que probé el modelo y lo podemos llevar a producción.\n",
    "# El valor que se comunica es el del conjunto de prueba!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Como usar este modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.- Partimos de una oración\n",
    "# 2.- Pasamos de textos a 1 y 0\n",
    "# 3.- Llamamos a nuestra predicción\n",
    "# Nota.- 0 es doctor, 1 político"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oración = \"Que pasara con la pandemia de covid 19 el proximo año de elecciones\"  # 1\n",
    "own_x = vectorizador_real.transform([oración])  # 2\n",
    "result = lr.predict(own_x)  # 3\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La frase fue dicha por un político"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Existe otro metodo que no es predict, disponible en regresion logistica, nos da una probabilidad de pertenencia a cad una de las clases.\n",
    "# Regresa un estimado de quien dijo la frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.246288180236956, 96.75371181976304)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medico, politico = lr.predict_proba(own_x).squeeze()*100\n",
    "medico, politico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Existe un 96% de probabilidad que la frase se haya dicho por un político"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ec8287a9e9ba415041c01db483634ecddc764051071c3300e0c5e030a2e30de"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
